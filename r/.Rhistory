library(RColorBrewer)
library(wordcloud)
pal = brewer.pal(9, "Set1")
wordcloud(names(wc2), freq=wc2, scale=scale, rot.per=0.25,
min.freq = 1, random.order = F, random.color = T, colors = pal)
}
draw_key_wordcolud(keyword = "백종원" , n = 100, since = '2019-03-01', until = '2019-03-24', draw_n = 50, scale = c(10, 0.5))
draw_key_wordcolud = function(keyword, n, draw_n, since, until){
tweets = searchTwitter(enc2utf8(keyword), n=n, lan='ko',
since=since, until=until)
tdf = twListToDF(tweets)
tw = unique(tdf$text)
tw = gsub("[[:cntrl:]]", "", tw)
tw = gsub("http[s]?://[[:alnum:].\\/]+", "", tw)
tw = gsub("&[[:alnum:]]+;", "", tw)
tw = gsub("RT @[[:alnum:][:punct:]]+[:]?", "", tw)
tw = gsub("[ㄱ-ㅎㅏ-ㅣ]","",tw)
tw = gsub("\\s{2,}", " ", tw)
tw = gsub("[[:punct:]]", "", tw)
tw = gsub('\\p{So}|\\p{Cn}', '', tw, perl = TRUE)
wc = sapply(tw, extractNoun, USE.NAMES = F)
ul = unlist(wc)
ul = ul[nchar(ul) > 1]
wc1 = table(ul)
wc2 = head(sort(wc1, decreasing = T), draw_n)
library(RColorBrewer)
library(wordcloud)
pal = brewer.pal(9, "Set1")
wordcloud(names(wc2), freq=wc2, scale=c(10,0.5), rot.per=0.25,
min.freq = 1, random.order = F, random.color = T, colors = pal)
}
draw_key_wordcolud(keyword = "백종원", n = 100, draw_n = 20, since = '2019-03-01', until = '2019-03-24')
tweets = searchTwitter(enc2utf8(keyword), n=n, lan='ko',
since=since, until=until)
tdf = twListToDF(tweets)
tw = unique(tdf$text)
tw
tw = gsub("[[:cntrl:]]", "", tw)
tw = gsub("http[s]?://[[:alnum:].\\/]+", "", tw)
tw = gsub("&[[:alnum:]]+;", "", tw)
tw = gsub("RT @[[:alnum:][:punct:]]+[:]?", "", tw)
tw = gsub("[ㄱ-ㅎㅏ-ㅣ]","",tw)
tw = gsub("\\s{2,}", " ", tw)
tw = gsub("[[:punct:]]", "", tw)
tw = gsub('\\p{So}|\\p{Cn}', '', tw, perl = TRUE)
wc = sapply(tw, extractNoun, USE.NAMES = F)
ul = unlist(wc)
ul = ul[nchar(ul) > 1]
wc1 = table(ul)
wc2 = head(sort(wc1, decreasing = T), draw_n)
wordcloud(names(wc2), freq=wc2, scale=c(10,0.5), rot.per=0.25,
min.freq = 1, random.order = F, random.color = T, colors = pal)
tw = unique(tdf$text)
tw
tw = gsub("[[:cntrl:]]", "", tw)
tw = gsub("http[s]?://[[:alnum:].\\/]+", "", tw)
tw = gsub("&[[:alnum:]]+;", "", tw)
tw = gsub("RT @[[:alnum:][:punct:]]+[:]?", "", tw)
tw = gsub("[ㄱ-ㅎㅏ-ㅣ]","",tw)
tw = gsub("\\s{2,}", " ", tw)
tw = gsub("[[:punct:]]", "", tw)
tw = gsub('\\p{So}|\\p{Cn}', '', tw, perl = TRUE)
wc = sapply(tw, extractNoun, USE.NAMES = F)
wc
ul = unlist(wc)
ul = ul[nchar(ul) > 1]
wc1 = table(ul)
wc1
wc2 = head(sort(wc1, decreasing = T), draw_n)
wc2
wc2
wordcloud(names(wc2), freq=wc2, scale=c(10,0.5), rot.per=0.25,
min.freq = 1, random.order = F, random.color = T, colors = pal)
wc2
wordcloud(names(wc2), freq=wc2, scale=c(20,0.5), rot.per=0.25,
min.freq = 1, random.order = F, random.color = T, colors = pal)
wordcloud(names(wc2), freq=wc2, scale=c(5,0.5), rot.per=0.25,
min.freq = 1, random.order = F, random.color = T, colors = pal)
wordcloud(names(wc2), freq=wc2, scale=c(10,0.5), rot.per=0.25,
min.freq = 1, random.order = F, random.color = T, colors = pal)
wordcloud(names(wc2), freq=wc2, scale=c(5,0.5), rot.per=0.25,
min.freq = 1, random.order = F, random.color = T, colors = pal)
wordcloud(names(wc2), freq=wc2, scale=c(10,1), rot.per=0.25,
min.freq = 1, random.order = F, random.color = T, colors = pal)
wordcloud(names(wc2), freq=wc2, scale=c(5, 0.5), rot.per=0.25,
min.freq = 1, random.order = F, random.color = T, colors = pal)
getwd()
save("./apikey/apikey.R")
save(file="./apikey/apikey.R")
getwd()
getwd()
save(api_key, file = "./apikey/twitter.rda")
keys=c(api_key, api_secret, token, token_secret)
save(api_key, file = "./apikey/twitter.rda")
save(api_key, file = "./apikey/twitter.rda")
load("~/workspace/hello/r/apikey/twitter.rda")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
theme_set(theme_gray(base_family = "AppleGothic"))
par(family = "AppleGothic")
library(twitteR); library(RCurl); library(RJSONIO); library(stringr)
library(streamR); library(ROAuth)
library(rJava); library(KoNLP)
library(SnowballC); library(RColorBrewer); library(wordcloud)
load("../apikey/twitter.rda")
keys[1]
load("~/workspace/hello/r/apikey/twitter.rda")
save(keys, file = "./apikey/twitter.rda")
save(keys, file = "./apikey/twitter.rda")
install.packages(c("arules", "igraph", "combinat", "arulesViz", "visNetwork"))
library(arules); library(igraph); library(combinat)
library(arules); library(igraph); library(combinat)
?apriori
nouns = sapply(wc, unique)
nouns1 = sapply(nouns, function(x) {
Filter(function(y='') { nchar(y) <= 4 && nchar(y) > 1 && is.hangul(y) }, x)
})
library(RMySQL)
library(tm)
source('~/workspace/hello/r/pre_preference.R', echo=TRUE)
nouns1 = sapply(nouns, function(x) {
Filter(function(y='') { nchar(y) <= 4 && nchar(y) > 1 && is.hangul(y) }, x)
})
wtrans = as(nouns1, "transactions")
rules = apriori(wtrans, parameter = list(supp=0.015, conf=0.5))
install.packages(c("arulesViz", "visNetwork"))
library(arulesViz); library(visNetwork)
# lift 기준으로 상위 20개만을 시각화
subrules2 <- head(sort(rules, by="lift"), 20)
ig <- plot( subrules2, method="graph", control=list(type="items") )
# interactive
ig_df <- get.data.frame( ig, what = "both" )
visNetwork(
nodes = data.frame(id = ig_df$vertices$name,
value = ig_df$vertices$support, ig_df$vertices),
edges = ig_df$edges
) %>% visEdges(ig_df$edges) %>%visOptions( highlightNearest = T )
?sapply
?try
?trySilent
# naver news
install.packages(c('rvest', 'httr', 'stringr'))
install.packages(c("rvest", "httr", "stringr"))
install.packages(c("rvest", "httr", "stringr"))
install.packages(c("rvest", "httr", "stringr"))
install.packages(c("rvest", "httr", "stringr"))
install.packages(c("rvest", "httr", "stringr"))
install.packages(c("rvest", "httr", "stringr"))
install.packages(c("rvest", "httr", "stringr"))
wtrans
rules = apriori(wtrans, parameter = list(supp=0.015, conf=0.5, minlen=2, maxlen=5))
nouns1
wtrans = as(nouns1, "transactions")
newsUrl = "https://news.naver.com/main/home.nhn"
html = read_html(newsUrl)
links = html_attr(html_nodes(html, '.main_component.droppable li a'), 'href')
library(rvest); library(httr); library(stringr); library(dplyr)
newsUrl = "https://news.naver.com/main/home.nhn"
html = read_html(newsUrl)
links = html_attr(html_nodes(html, '.main_component.droppable li a'), 'href')
links = links[!is.na(links)]
news = list()
j = 1
for (i in 1:5) {
try({
# htxt = read_html(paste0('https://news.naver.com', links[i]))
htxt = read_html(links[i])
comments = html_nodes(htxt, '#articleBodyContents')
# repair_encoding(html_text(comments), from='utf-8')
get_news = repair_encoding(html_text(comments))
if(is.null(get_news)) next
news[j] = str_trim(get_news)
j = j + 1
# ch = html_children(comments)
# for (i in 1:length(ch)) {
#   chtxt = html_text(ch[i])
#   if (chtxt == "") next
#   get_news = stri_replace_all(get_news, "", fixed=html_text(ch[i]))
# }
}, silent = F)
}
news
length(news)
news1 = news
for (i in 1:length(news1)){
try({news1[[i]][1] = removeStopword(news1[[i]][1])
news1[[i]][1] = gsub('function flashremoveCallback',' ', news1[[i]][1])}, silent = T)
}
for (i in 1:length(news1)){
try({news1[[i]][1] = removeStopword(news1[[i]][1])
news1[[i]][1] = gsub('function flashremoveCallback',' ', news1[[i]][1])}, silent = T)
}
news1
removeStopword = function(tw){
tw = gsub("\\s{2,}", " ", tw)
tw = gsub("[[:cntrl:]]", " ", tw)
tw = gsub("http[s]?://[[:alnum:].\\/]+", " ", tw)
tw = gsub('[[:alnum:].]+@[[:alnum:].]+', ' ', tw)
tw = gsub("&[[:alnum:]]+;", " ", tw)
tw = gsub("RT @[[:alnum:][:punct:]]+[:]?", " ", tw)
tw = gsub("[ㄱ-ㅎㅏ-ㅣ]"," ",tw)
tw = gsub("\\s{2,}", " ", tw)
tw = gsub("[[:punct:]]", " ", tw)
# tw = gsub("flash 오류를 우회하기 위한 함수 추가 function flash removeCallback",'', tw)
tw = gsub('flash 오류를 우회하기 위한 함수 추가','',tw)
tw = gsub('function flashremoveCallback',' ', tw)
tw = gsub("function flash removeCallback", " ", tw)
tw = gsub("_flash_removeCallback()", " ", tw)
tw = gsub('\\p{So}|\\p{Cn}', '', tw, perl = TRUE)
tw = gsub("\\s{2,}", " ", tw)
}
for (i in 1:length(news1)){
try({news1[[i]][1] = removeStopword(news1[[i]][1])
news1[[i]][1] = gsub('function flashremoveCallback',' ', news1[[i]][1])}, silent = T)
}
news1
# 수집 된 뉴스로 WordCloud를 작도하시오.
library(rJava); library(KoNLP)
wc = head(sapply(news1, extractNoun, USE.NAMES = F), 30)
data_unlist = unlist(wc)
data_unlist <- Filter(function(x){nchar(x)>=2}, data_unlist)
wc1 = table(data_unlist)
wc1
names(wc1); length(wc1)
pal = brewer.pal(9, "Set1")
wordcloud(names(wc2), freq=wc2, scale=c(2,0.05), rot.per=0.5,
min.freq = 1, random.order = F, random.color = T, colors = pal)
library(RColorBrewer); library(wordcloud)
pal = brewer.pal(9, "Set1")
wordcloud(names(wc2), freq=wc2, scale=c(2,0.05), rot.per=0.5,
min.freq = 1, random.order = F, random.color = T, colors = pal)
wc3 = head(sort(wc1, decreasing = T), 600)
library(arules); library(igraph); library(combinat)
nouns = sapply(wc, unique)
nouns1 = sapply(nouns, function(x) {
Filter(function(y='') { nchar(y) > 1 && nchar(y) <= 4}, x)
})
wtrans = as(nouns1, "transactions")
rules = apriori(wtrans, parameter = list(supp=0.5, conf=0.5, minlen=2, maxlen=5))
library(arulesViz); library(visNetwork)
subrules2 <- head(sort(rules, by="lift"), 20) ## lift 기준으로 상위 20개만을 시각화
ig <- plot( subrules2, method="graph", control=list(type="items") )
source('~/workspace/hello/r/pre_preference.R', echo=TRUE)
source('~/workspace/hello/r/pre_preference.R', echo=TRUE)
data
data %>% filter(반 %in% c('매', '죽'))
data %>% filter(반 %in% c('매', '죽')) %>% select(반, 국어)
data1
data2
data21
data22
data %>% filter(반 %in% c('매', '죽')) %>% select(반, 수학)
data %>% filter(반 %in% c('매', '죽')) %>% select(반, 수학) -> sampledata
summary(sampledata)
head(sampledata)
describeBy(sampledata$수학, mnkor$cls, mat = T)
library(psych)
describeBy(sampledata$수학, mnkor$cls, mat = T)
describeBy(sampledata$수학, sampledata$반, mat = T)
sampledata
describeBy(data$수학, data$반, mat = T)
describeBy(sampledata$수학, sampledata$반, mat = T)
sampledata$반 = factor(sampledata$반, levels=c('매', '죽'), labels=c('매', '죽'))
describeBy(sampledata$수학, sampledata$반, mat = T)
boxplot(sampledata$수학 ~ sampledata$반)
layout(matrix(c(1,1,2,3), 2, 2, byrow = T))
boxplot(sampledata$수학 ~ sampledata$반)
hist(sampledata$수학[sampledata$반 == '매'])
hist(sampledata$수학[sampledata$반 == '죽'])
par(orgpar)
orgpar = par(no.readonly = T)
par(orgpar)
var.test(sampledata$수학 ~ sampledata$반, data = sampledata)
t.test(sampledata$수학 ~ sampledata$반, data = sampledata,
alternative = c("two.sided"),
var.equal = T,                 # 등분산검증의 p-value < 0.05 이면 False로!
conf.level = 0.95)
bartlett.test(sampledata$수학 ~ sampledata$반, data=sampledata)
var.test(sampledata$수학 ~ sampledata$반, data = sampledata)
t.test(sampledata$수학 ~ sampledata$반, data = sampledata,
alternative = c("two.sided"),
var.equal = T,                 # 등분산검증의 p-value < 0.05 이면 False로!
conf.level = 0.95)
describeBy(sampledata$수학, sampledata$반, mat = T)
# 5. 결과 graph 작도
mu = 63.84167; se = 2.114145; rn = sort(rnorm(120, mu, se))  #describeBy의 첫번째 그룹의 mean, se
par(orgpar)
# 5. 결과 graph 작도
mu = 63.84167; se = 2.114145; rn = sort(rnorm(120, mu, se))  #describeBy의 첫번째 그룹의 mean, se
plot(rn, dnorm(rn, mu, se), col='green', type = 'l', main = '평균점수',
xlim = c(20, 100), ylim = c(0, 0.25))
data %>% filter(반 %in% c('매', '죽')) %>% select(반, 수학) -> sampledata
source('~/workspace/hello/r/pre_preference.R', echo=TRUE)
data %>% filter(반 %in% c('매', '죽')) %>% select(반, 수학) -> sampledata
head(sampledata)
summary(sampledata)
sampledata$반 = factor(sampledata$반, levels=c('매', '죽'), labels=c('매', '죽'))
library(psych)
describeBy(sampledata$수학, sampledata$반, mat = T)
## 2. 데이터 분석(표본 데이터 확인)
boxplot(sampledata$수학 ~ sampledata$반)
orgpar = par(no.readonly = T)
## 2. 데이터 분석(표본 데이터 확인)
orgpar = par(no.readonly = T)
boxplot(sampledata$수학 ~ sampledata$반)
layout(matrix(c(1,1,2,3), 2, 2, byrow = T))
boxplot(sampledata$수학 ~ sampledata$반)
hist(sampledata$수학[sampledata$반 == '매'])
hist(sampledata$수학[sampledata$반 == '죽'])
par(orgpar)
var.test(sampledata$수학 ~ sampledata$반, data = sampledata)  # p-value = 0.876
t.test(sampledata$수학 ~ sampledata$반, data = sampledata,
alternative = c("two.sided"),
var.equal = T,                 # 등분산검증의 p-value < 0.05 이면 False로!
conf.level = 0.95)             # p-value = 0.901 > 0.05(=1-a)
# 5. 결과 graph 작도
mu = 63.84167; se = 2.114145; rn = sort(rnorm(120, mu, se))  #describeBy의 첫번째 그룹의 mean, se
plot(rn, dnorm(rn, mu, se), col='green', type = 'l', main = '평균점수',
xlim = c(20, 100), ylim = c(0, 0.25))
par(new = T)          # 겹쳐 그리기
mu =63.46667; se = 2.144661; rn = sort(rnorm(120, mu, se)) #describeBy의 두번째 그룹의 mean, se
plot(rn, dnorm(rn, mu, se), col='red', type = 'l', main = '평균점수',
xlim = c(20, 100), ylim = c(0, 0.25))
abline(v=mu, col="red", lty=5)
par(orgpar)
# 5. 결과 graph 작도
mu = 63.84167; se = 2.114145; rn = sort(rnorm(120, mu, se))  #describeBy의 첫번째 그룹의 mean, se
plot(rn, dnorm(rn, mu, se), col='green', type = 'l', main = '평균점수',
xlim = c(20, 100), ylim = c(0, 0.25))
abline(v=mu, col="green", lty=5)
par(new = T)          # 겹쳐 그리기
mu =63.46667; se = 2.144661; rn = sort(rnorm(120, mu, se)) #describeBy의 두번째 그룹의 mean, se
plot(rn, dnorm(rn, mu, se), col='red', type = 'l', main = '평균점수',
xlim = c(20, 100), ylim = c(0, 0.25))
abline(v=mu, col="red", lty=5)
par(orgpar)
# 5. 결과 graph 작도
mu = 63.84167; se = 2.114145; rn = sort(rnorm(120, mu, se))  #describeBy의 첫번째 그룹의 mean, se
plot(rn, dnorm(rn, mu, se), col='green', type = 'l', main = '평균점수',
xlim = c(40, 80), ylim = c(0, 0.25))
abline(v=mu, col="green", lty=5)
# 5. 결과 graph 작도
mu = 63.84167; se = 2.114145; rn = sort(rnorm(120, mu, se))  #describeBy의 첫번째 그룹의 mean, se
plot(rn, dnorm(rn, mu, se), col='green', type = 'l', main = '평균점수',
xlim = c(50, 80), ylim = c(0, 0.25))
abline(v=mu, col="green", lty=5)
par(new = T)          # 겹쳐 그리기
mu =63.46667; se = 2.144661; rn = sort(rnorm(120, mu, se)) #describeBy의 두번째 그룹의 mean, se
plot(rn, dnorm(rn, mu, se), col='red', type = 'l', main = '평균점수',
xlim = c(40, 80), ylim = c(0, 0.25))
abline(v=mu, col="red", lty=5)
par(orgpar)
# 5. 결과 graph 작도
mu = 63.84167; se = 2.114145; rn = sort(rnorm(120, mu, se))  #describeBy의 첫번째 그룹의 mean, se
plot(rn, dnorm(rn, mu, se), col='green', type = 'l', main = '평균점수',
xlim = c(50, 80), ylim = c(0, 0.25))
abline(v=mu, col="green", lty=5)
par(new = T)          # 겹쳐 그리기
mu =63.46667; se = 2.144661; rn = sort(rnorm(120, mu, se)) #describeBy의 두번째 그룹의 mean, se
plot(rn, dnorm(rn, mu, se), col='red', type = 'l', main = '평균점수',
xlim = c(50, 80), ylim = c(0, 0.25))
abline(v=mu, col="red", lty=5)
par(orgpar)
# 5. 결과 graph 작도
mu = 63.84167; se = 2.114145; rn = sort(rnorm(120, mu, se))  #describeBy의 첫번째 그룹의 mean, se
plot(rn, dnorm(rn, mu, se), col='green', type = 'l', main = '평균점수',
xlim = c(55, 75), ylim = c(0, 0.25))
abline(v=mu, col="green", lty=5)
par(new = T)          # 겹쳐 그리기
mu =63.46667; se = 2.144661; rn = sort(rnorm(120, mu, se)) #describeBy의 두번째 그룹의 mean, se
plot(rn, dnorm(rn, mu, se), col='red', type = 'l', main = '평균점수',
xlim = c(55, 75), ylim = c(0, 0.25))
abline(v=mu, col="red", lty=5)
par(orgpar)
describeBy(sampledata$수학, sampledata$반, mat = T)
## 1. 데이터 분석(표본 및 기술 통계 확인)
data
## 1. 데이터 분석(표본 및 기술 통계 확인)
data
data
describeBy(data$수학, data$반, mat = T)
describeBy(sampledata$수학, sampledata$반, mat = T)
data %>% select(반, 수학)
data %>% select(반, 수학) -> sampledata1
describeBy(sampledata1$수학, sampledata1$반, mat = T)
describeBy(sampledata1$수학, sampledata1$반, mat = T) -> summary_sampledata1
summary_sampledata1 %>% select(group1, mean, se)
summary_sampledata1 %>% select(group1, mean, se) -> summary_sampledata1
ggplot(data, aes(x=cls, y=kor)) +
geom_boxplot(outlier.color = 'blue') +
ggtitle("각반 국어 성적")
ggplot(sampledata1, aes(x=반, y=수학)) +
geom_boxplot(outlier.color = 'blue') +
ggtitle("각반 수학 성적")
ggplot(sampledata1, aes(x=수학)) +
geom_histogram(binwidth = 10, col='white') +
facet_grid(. ~ sampledata1$반)
bartlett.test(sampledata1$수학 ~ sampledata1$반, data=sampledata1)
aov(sampledata1$수학 ~ sampledata1$반, data=sampledata1)
aov(sampledata1$수학 ~ sampledata1$반, data=sampledata1) -> aaa
summary(aaa)
draw = function(rn, mu, se, col) {
plot(rn, dnorm(rn, mu, se), col=col, type = 'l',
xlim = c(50, 80), ylim = c(0, 0.25))
abline(v=mu, col=col, lty=5)
}
par(orgpar)
mu = 62.6; se = 2.097331; rn = sort(rnorm(1000, mu, se))
draw(rn, mu, se, 'red')
par(new = T)
mu = 59.4; se = 1.975140; rn = sort(rnorm(1000, mu, se))
draw(rn, mu, se, 'blue')
par(new = T)
mu = 64.2833; se = 1.9523; rn = sort(rnorm(1000, mu, se))
draw(rn, mu, se, 'darkgreen')
par(new = T)
mu = 66.6; se = 1.964653; rn = sort(rnorm(1000, mu, se))
draw(rn, mu, se, 'black')
par(orgpar)
legend('topright',
legend=c('국', '난', '매', '죽'),
pch=8,
col=c('red', 'blue', 'darkgreen', 'black'),
bg='gray')
data
## 4-1. 사후검정
TukeyHSD(aaa)
## 4-2. 동질성 결과 그래프
plot(TukeyHSD(aaa))       # 가운데 선이 0이면 일치
data
data %>% select(국어, 영어)
data %>% select(국어, 영어) -> sampledata2
head(sampledata2)
describe(sampledata2)
pairs.panels(sampledata2)
sampledata2
# 4. 상관분석
cor(cdata, use = "complete.obs",   # 결측치(NA) 제외
method = c("pearson"))         # 모수 통계  cf. 비모수(30개 미만)의 경우 spearman)
# 4. 상관분석
cor(sampledata2, use = "complete.obs",   # 결측치(NA) 제외
method = c("pearson"))         # 모수 통계  cf. 비모수(30개 미만)의 경우 spearman)
plot(국어 ~ 영어, data=sampledata2)
abline(lm(국어 ~ 영어, data=sampledata2), col='red')
mpg
unique(mpg$trans); unique(mpg$year);
unique(mpg$trans)
sampledata3 = mpg %>%
mutate(trs = ifelse(substr(trans, 1, 4) == 'auto', 1, 0),
y = ifelse(year == 1999, 0, 1)) %>%
select(y, displ, cyl, trs, cty, hwy)
sampledata3
head(sampledata3, 10)
describe(cdata3)
describe(sampledata3)
pairs.panels(sampledata3)
# 3. 분석
glmdata = glm(y ~ displ+cyl+cty+hwy+trs, family = binomial, data=sampledata3)
glm(y ~ displ+cyl+cty+hwy+trs, family = binomial, data=sampledata3)
summary(glmdata)  # Estimate: 기울기(비례/반비례), Pr: 0.05보다 작으면 영향이 있다
plot(glmdata)
orgpar = par(no.readonly = T)
orgpar = par(no.readonly = T)
par(mfrow=c(2,2))
plot(glmdata)
par(orgpar)
exp(cbind(LOR = coef(glmdata), confint(glmdata))
)
glmdata = glm(y ~ displ+cty+hwy+trs, family = binomial, data=sampledata3)
summary(glmdata)  # Estimate: 기울기(비례/반비례), Pr: 0.05보다 작으면 영향이 있다
orgpar = par(no.readonly = T)
par(mfrow=c(2,2))
plot(glmdata)
par(orgpar)
# 4. coefficients(기울기+절편)와 confint(신뢰구간)로 LOR(Log Odd Ratio) 구하기
round(exp(cbind(LOR = coef(glmdata), confint(glmdata))), 2)
glmdata = glm(y ~ displ+cyl+hwy+trs, family = binomial, data=sampledata3)
summary(glmdata)  # Estimate: 기울기(비례/반비례), Pr: 0.05보다 작으면 영향이 있다
orgpar = par(no.readonly = T)
par(mfrow=c(2,2))
plot(glmdata)
par(orgpar)
# 4. coefficients(기울기+절편)와 confint(신뢰구간)로 LOR(Log Odd Ratio) 구하기
round(exp(cbind(LOR = coef(glmdata), confint(glmdata))), 2)
# 3. 분석
glmdata = glm(y ~ displ+cyl+cty+hwy+trs, family = binomial, data=sampledata3)
summary(glmdata)  # Estimate: 기울기(비례/반비례), Pr: 0.05보다 작으면 영향이 있다
glmdata = glm(y ~ displ+hwy, family = binomial, data=sampledata3)
orgpar = par(no.readonly = T)
par(mfrow=c(2,2))
plot(glmdata)
par(orgpar)
# 4. coefficients(기울기+절편)와 confint(신뢰구간)로 LOR(Log Odd Ratio) 구하기
round(exp(cbind(LOR = coef(glmdata), confint(glmdata))), 2)
# 3. 분석
glmdata = glm(y ~ displ+cyl+cty+hwy+trs, family = binomial, data=sampledata3)
# 4. coefficients(기울기+절편)와 confint(신뢰구간)로 LOR(Log Odd Ratio) 구하기
round(exp(cbind(LOR = coef(glmdata), confint(glmdata))), 2)
save(data, file = 'data/data.rda')
knitr::opts_chunk$set(echo = TRUE)
data
data %>% select('국어', '영어') -> sampledata2
head(sampledata2)
data %>% select(국어, 영어) -> sampledata2
data %>% select(국어, 영어) -> sampledata2
load("../data/data_eng.rda")
getwd()
load("./data/data_eng.rda")
data
knitr::opts_chunk$set(echo = TRUE)
data
